{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MyShallowNetwork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKF6T5jRC4mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "dataset=load_breast_cancer()\n",
        "X, y = dataset.data, dataset.target\n",
        "m=X.shape[1]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoF6ZEKGxEKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataset preprocessing\n",
        "X_scaled = preprocessing.scale(X)             #Now all the features are standardized in this (m,n_x) matrix\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,test_size=0.33,random_state=0)\n",
        "X_train,X_test = X_train.T,X_test.T                                        #Reshaping it to be (n_x,num example) matrices\n",
        "y_train,y_test = y_train.reshape([1,y_train.shape[0]]),y_test.reshape([1,y_test.shape[0]])   #Reshaping it to be (1, num_example) matrices\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXwitQrXIdi0",
        "colab_type": "code",
        "outputId": "385da880-547d-4760-e4b0-fbbbaabfc54e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(\"The shape of X: \" + str(X.shape))\n",
        "print(\"The shape of y: \" + str(y.shape))\n"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The shape of X: (569, 30)\n",
            "The shape of y: (569,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huc_sFTODJHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def sigmoid(Z):\n",
        "    return 1/(1+np.exp(-Z))\n",
        "    \n",
        "\n",
        "def relu(Z):\n",
        "    return np.maximum(0,Z)\n",
        "\n",
        "def tanh(Z):\n",
        "    return  (np.exp(Z) - np.exp(-Z))/(np.exp(Z) + np.exp(-Z))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csLLPu5LFkuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dSigmoid(Z):\n",
        "        return sigmoid(Z)*(1-sigmoid(Z))\n",
        "\n",
        "def drelu(Z):\n",
        "        return Z > 0\n",
        "\n",
        "def dtanh(Z):\n",
        "        return 1 - np.power(tanh(Z),2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKvCsgZUFm-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(n_x,n_h,n_y):\n",
        "\n",
        "\n",
        "        W1 = np.random.randn(n_h,n_x)*0.01                                   # The values of weight is put small to prevent saturation of gradients. Since the network is smaller we need not worry about exploding or vanishing\n",
        "        b1 = np.zeros([n_h,1])\n",
        "        W2 = np.random.randn(n_y,n_h)*0.01                                      \n",
        "        b2 = np.zeros([n_y,1])\n",
        "        \n",
        "        assert (W1.shape == (n_h, n_x))\n",
        "        assert (b1.shape == (n_h, 1))\n",
        "        assert (W2.shape == (n_y, n_h))\n",
        "        assert (b2.shape == (n_y, 1))\n",
        "\n",
        "        parameters = {\n",
        "                \"W1\" : W1,\n",
        "                \"b1\" : b1,\n",
        "                \"W2\" : W2,\n",
        "                \"b2\" : b2\n",
        "        }\n",
        "\n",
        "        return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "574s1OJbHuYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cross_entropy_cost(A2,Y,m):\n",
        "        \"\"\" Cost function\n",
        "                input: A2 (final activation) [1,m]\n",
        "                        Y(ground truth)      [1,m]\n",
        "                        m(no. of training examples)\n",
        "\n",
        "                output: J cost function \"\"\" \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        logprobs = Y*np.log(A2) + (1-Y)*np.log(1-A2)   ##Calculates the element wise matrix multiplication \n",
        "        cost = -1/m*np.sum(logprobs)                   ##Sums them and returns cost\n",
        "        cost = np.squeeze(cost)                        ##Ensure cost is a single number\n",
        "        return cost\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DgfBH1ZH0gB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_prop(X,parameters):\n",
        "    \"\"\"Computes forward propagation \n",
        "        \n",
        "       input: X of shape(n_x,m) (feature space)\n",
        "       parameters: dictionary containing Weights and biases\n",
        "       \n",
        "       return : (A2)\"\"\"\n",
        "\n",
        "\n",
        "    m = X.shape[1]\n",
        "    W1=parameters['W1']\n",
        "    b1=parameters['b1']\n",
        "    W2=parameters['W2']\n",
        "    b2=parameters['b2']\n",
        "    \n",
        "    #print(\"Shape of W1 is : \" + str(W1.shape))\n",
        "    #print(\"Shape of b1 is : \" + str(b1.shape))\n",
        "    #print(\"Shape of W2 is : \" + str(W2.shape))\n",
        "    #print(\"Shape of b2 is : \" + str(b2.shape))\n",
        "\n",
        "    Z1= np.dot(W1,X) + b1\n",
        "    A1=relu(Z1)\n",
        "    Z2 =np.dot(W2,A1) + b2\n",
        "    A2= sigmoid(Z2)\n",
        "    \n",
        "    \n",
        "    \n",
        "    cache = {\n",
        "        \"Z1\" : Z1,\n",
        "        \"Z2\" : Z2,\n",
        "        \"A1\" : A1,\n",
        "        \"A2\" : A2\n",
        "    }\n",
        "    \n",
        "    return A2,cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBfmEPFfH8Ei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def back_prop(X,cache,parameters,Y):\n",
        "        \"\"\" Algorithm for backward propagation \n",
        "                input : cache, dictionary contain X,Z1,Z2,A1,A2\n",
        "                output: gradients, dictionary containing dZ1,db1,dZ2,db2 \"\"\"\n",
        "       \n",
        "       \n",
        "        m = Y.shape[1]                       # No. of training examples\n",
        "       \n",
        "        \n",
        "        # Initialization\n",
        "        W2=parameters['W2']                  \n",
        "        A1=cache['A1']  \n",
        "        A2=cache['A2']\n",
        "        Z1=cache['Z1']\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "    \n",
        "\n",
        " \n",
        "        dZ2 = A2 - Y\n",
        "        dW2 = 1/m *np.dot(dZ2,A1.T)\n",
        "        db2 = 1/m*np.sum(dZ2,axis=1, keepdims = True)\n",
        "\n",
        "\n",
        "        dZ1  = np.dot(W2.T,dZ2)*drelu(Z1)\n",
        "        dW1 = 1/m* np.dot(dZ1,X.T)\n",
        "        db1 = 1/m*np.sum(dZ1,axis=1, keepdims = True)\n",
        "\n",
        "        gradients = {\n",
        "                \n",
        "                \"dW2\"   : dW2,\n",
        "                \"db2\"   : db2,\n",
        "                \"dW1\"   : dW1,\n",
        "                \"db1\"   : db1\n",
        "        }\n",
        "\n",
        "        return gradients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJK_jUV9IFsg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_parameters(parameters,gradients,learning_rate):\n",
        "        \"\"\" Updates all the parameters per iteration \"\"\"\n",
        "        \n",
        "\n",
        "\n",
        "        ## Extracting values from dictionary\n",
        "        W1=parameters['W1']\n",
        "        b1=parameters['b1']\n",
        "        W2=parameters['W2']\n",
        "        b2=parameters['b2']\n",
        "\n",
        "        dW1=gradients['dW1']\n",
        "        dW2=gradients['dW2']\n",
        "        db1=gradients['db1']\n",
        "        db2=gradients['db2']\n",
        "\n",
        "        #Update\n",
        "\n",
        "        W1 += -learning_rate*dW1\n",
        "        W2 += -learning_rate*dW2\n",
        "        b1 += -learning_rate*db1\n",
        "        b2 += -learning_rate*db2\n",
        "\n",
        "        updated_params={\n",
        "                \"W1\" : W1,\n",
        "                \"W2\" : W2,\n",
        "                \"b1\" : b1,\n",
        "                \"b2\" : b2\n",
        "        }\n",
        "\n",
        "        return updated_params\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZeNm4NgIKmC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad_des(X,num_iterations,learning_rate,Y):\n",
        "\n",
        "    n_x = X.shape[0]\n",
        "    n_h = 4                                                             ##Hard coding this to be 4 units hidden layer\n",
        "    n_y = Y.shape[0]\n",
        "    m=X.shape[1]\n",
        "    parameters = initialize_parameters(n_x,n_h,n_y)\n",
        "   \n",
        "    for _ in range(num_iterations):\n",
        "\n",
        "        A2,cache = forward_prop(X,parameters)\n",
        "        gradients=back_prop(X,cache,parameters,Y)\n",
        "        parameters=update_parameters(parameters,gradients,learning_rate)\n",
        "        \n",
        "        \n",
        "        #print(\"Cost: \" + str(cross_entropy_cost(A2,Y,m)))\n",
        "        \n",
        "\n",
        "    \n",
        "    print(\"Cost: \" + str(cross_entropy_cost(A2,Y,m)))\n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O12RsuO1bdYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X,parameters):\n",
        "    \n",
        "     A2,_=forward_prop(X,parameters)\n",
        "     return A2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBHDJ8lIIOiL",
        "colab_type": "code",
        "outputId": "c6212cbc-8ef7-402c-e8cb-fc3a6aba2e71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "parameters=grad_des(X_train,15000,0.005,y_train)\n",
        "\n",
        "prediction_train=predict(X_train,parameters)\n",
        "prediction_train=np.round(prediction_train)\n",
        "\n",
        "prediction_test=predict(X_test,parameters)\n",
        "prediction_test=np.round(prediction_test)\n",
        "\n",
        "m_train= X_train.shape[1]\n",
        "m_test=X_test.shape[1]\n",
        "print(X_train.shape)\n",
        "print(\"Training Accuracy is: \" +str(np.sum(prediction_train == y_train)*1/m_train*100 )+\"%\")\n",
        "print(\"Test Accuracy is: \" +str(np.sum(prediction_test == y_test)*1/m_test*100 )+\"%\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost: 0.051938078743140985\n",
            "(30, 381)\n",
            "Training Accuracy is: 98.68766404199475%\n",
            "Test Accuracy is: 98.40425531914893%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfiNHwVOIWOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH5yx0C_w712",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}